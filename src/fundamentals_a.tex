\chapter{Fundamentals Ⅰ: Many-Body Quantum Mechanics and Density Functional Theory}
\label{cha:fundamentals_a}

\section{A story starts from time evolution quantum mechanics}

Imagine that we are watching a microscopic play, with electrons and atoms as the actors. You blink, and suddenly the stage configuration has shifted. Something has changed. But how do we describe this evolution in physical language?

In classical physics, we started with Newton’s laws to describe the motions. Later, lagrangian and hamiltonian mechanics provided another description of physics from the perspective of degrees of freedom, symmetries, and conservations. Then came the great 20th-century revolution in physics, which developed the consensus of the microscopic scale, and quantum mechanics emerged. In this new framework, that role is played by the Schrödinger equation.

\subsection{Time-dependent Schrödinger equation}

In quantum mechanics, the state of a physical system at a given instant is represented by a vector $\ket{\psi(t)}$.
In a chosen representation, the same state can be expressed as a wavefunction.
This state vector encapsulates all information required to predict the statistics of measurement outcomes at time $t$.

The time evolution of the state is determined by the hamiltonian operator $\hat{H}$.
It corresponds to the total energy of the system.
For a closed system with a time-independent hamiltonian, the expectation value of the energy is conserved. This evolution is described by the time-dependent Schrödinger equation~\cite{shankar2012principles}:

\begin{equation}
    i\hbar\frac{\partial}{\partial t}\ket{\psi(t)}=\hat{H}\ket{\psi(t)}
    \label{time-dependent_Schrodinger_equation}
\end{equation}

here, the left-hand side gives the time derivative of the state vector;
the right-hand side shows that this change is generated by the action of the hamiltonian operator.

Suppose we know the state vector at an initial time $t=t_0$. This elegant equation then uniquely determines its future state and, in turn, the probabilities of measurement outcomes.

\subsection{Time evolution operator}

Suppose that the hamiltonian is independent of time, so that it does not depend explicitly on $t$.
In this case, the Schrödinger equation admits a formal solution.
Given a reference state vector $\ket{\psi(t_0)}$,
the state at time $t$ can be expressed with the time-evolution operator $\hat{U}(t,t_0)$:

\begin{equation}
    \ket{\psi(t)}=\hat{U}(t,t_0)\ket{\psi(t_0)}
    \label{state_time_evolution}
\end{equation}

Subsequently, we introduce the explicit exponential representation of the time-evolution operator:

\begin{equation}
    \hat{U}(t,t_0)=\mathrm{e}^{-\frac{\mathrm{i}}{\hbar}\hat{H}(t-t_0)}
    \label{time_evolution_operator}
\end{equation}

With the time difference $\tau=t-t_0$, we can express the time-evolution as a single-parameter family $\hat{U}(\tau)$:

\begin{equation}
    \hat{U}(\tau)=\mathrm{e}^{-\frac{\mathrm{i}}{\hbar}\hat{H}\tau}
    \label{time_evolution_operator_tau}
\end{equation}

If we stipulate $t_0=0$, this expression becomes:

\begin{equation}
    \hat{U}(t)=\mathrm{e}^{-\frac{\mathrm{i}}{\hbar}\hat{H}t}
    \label{time_evolution_operator_degeneration}
\end{equation}

We use $\hat{U}(t,t_0)$ to propagate the state forward in time while preserving its norm.
Since $\hat{H}$ is Hermitian, $\hat{U}(t,t_0)$ is unitary.
This property can be described as:

\begin{equation}
    \hat{U}^\dagger(t,t_0)\,\hat{U}(t,t_0)=\hat{U}(t,t_0)\,\hat{U}^\dagger(t,t_0) = \hat{I}
    \label{evolution_unitarity}
\end{equation}

Starting from the unitarity of $\hat{U}(t,t_0)$, quantum time evolution is reversible.
Here, we denote the evolution from time $t$ back to the reference time $t_0$ as $\hat{U}(t_0,t)$:

\begin{equation}
    \hat{U}^{\dagger}(t,t_0)= \hat{U}^{-1}(t,t_0) = \hat{U}(t_0,t)
\label{time_evolution_reversible}
\end{equation}

In the present time-independent case, we can further show that the Hermitian conjugate corresponds to evolving backward in time.
In terms of the time difference $\tau$, this relation can be written as:

\begin{equation}
    \hat{U}^{\dagger}(\tau)= \hat{U}^{-1}(\tau) = \hat{U}(-\tau)
\label{time_evolution_reversible_tau}
\end{equation}

% Accordingly, in the stipulation of $t=t_0$, this expression degenerates into:
Accordingly, if we choose $t_0=0$, this expression becomes:

\begin{equation}
    \hat{U}^{\dagger}(t)= \hat{U}^{-1}(t)= \hat{U}(-t)
\label{time_evolution_reversible_deg}
\end{equation}

The two-time evolution operator $\hat{U}(t,t_0)$ maps a quantum state from the reference time $t_0$ to time $t$.
By construction, successive time evolutions must be consistent with each other.
This requirement leads to the composition law:

\begin{equation}
    \hat{U}(t_2,t_0)=\hat{U}(t_2,t_1)\hat{U}(t_1,t_0)
    \label{composition_law_time_evolution}
\end{equation}

In the time-independent case, $\hat{U}(t,t_0)$ depends only on the time difference $\tau=t-t_0$.
The operators $\hat{U}(\tau)$ therefore forms a one-parameter unitary group:

\begin{equation}
    \hat{U}(\tau_2)\,\hat{U}(\tau_1)=\hat{U}(\tau_2+\tau_1)
    \label{time_evolution_group_property_tau}
\end{equation}

In particular, when we choose $t_0=0$, the one-parameter composition law becomes:

\begin{equation}
    \hat{U}(t_1+t_2)=\hat{U}(t_1)\,\hat{U}(t_2)
    \label{time_evolution_group_property}
\end{equation}

For the one-parameter family $\hat{U}(\tau)$, the identity element, $\hat{I}$, corresponds to $\tau=0$:

\begin{equation}
    \hat{U}(0)=\hat{I}
    \label{time_evolution_identity}
\end{equation}

In this sense, these relations mean that time translation can be composed consistently, and that the evolution can always be undone by evolving backward.

Unitarity also guarantees probability conservation.
If the state is normalized at time $t_0$, it remains normalized for all later times:

\begin{equation}
\begin{aligned}
    \braket{\psi(t)|\psi(t)}
    &= \bra{\psi(t_0)}\hat{U}^{\dagger}(t,t_0)\,\hat{U}(t,t_0)\ket{\psi(t_0)} \\
    &= \bra{\psi(t_0)}\hat{I}\ket{\psi(t_0)} \\
    &= \braket{\psi(t_0)|\psi(t_0)}
\end{aligned}
\label{time_evolution_norm_conservation}
\end{equation}

If the state is normalized at time $t_0$, then $\braket{\psi(t_0)|\psi(t_0)}=1$, and the state remains normalized for all later times.

This is why we can view $\hat{U}(t,t_0)$ as the quantum analogue of a time-translation operator.
It moves the state through Hilbert space without changing its total probability.

Finally, for a small time step $\Delta t$, we return to the exponential form:

\begin{equation}
    \hat{U}(\Delta t)=\mathrm{e}^{-\frac{\mathrm{i}}{\hbar}\hat{H}\Delta t}
    \label{time_evolution_short_time_exact}
\end{equation}

and obtain the short-time expansion:

\begin{equation}
    \hat{U}(\Delta t)\approx \hat{I}-\frac{\mathrm{i}}{\hbar}\hat{H}\Delta t+\mathcal{O}(\Delta t^2)
    \label{time_evolution_short_time_series}
\end{equation}

Acting on $\ket{\psi(t)}$ and taking the limit $\Delta t\to 0$ then recovers the differential form of the time-dependent Schrödinger equation.

% \subsection{Generalizing to time-dependent hamiltonians}

We now consider the more general case in which the hamiltonian depends explicitly on time and is denoted by $\hat{H}(t)$.
The state is still propagated by the evolution operator $\hat{U}(t_1,t_0)$ as in equationon~\eqref{state_time_evolution}.

In this case, its corresponding time-evolution operator can be written as a time-ordered exponential~\cite{sakurai2020modern}:

\begin{equation}
    \hat{U}(t_1,t_0)=\hat{T}\exp\left(-\frac{\mathrm{i}}{\hbar}\int_{t_0}^{t_1}\hat{H}(t)\mathrm{d}t\right)
    \label{time-ordering_operator}
\end{equation}

here $\hat{T}$ denotes the time-ordering operator.
It orders products of $\hat{H}(t)$ such that operators at later times appear to the left.
This is required when the hamiltonians at different times do not commute:

\begin{equation}
    [\hat{H}(t),\hat{H}(t')]\neq 0
    \label{hamiltonian_noncommutativity}
\end{equation}

Equivalently, the hamiltonian operators evaluated at earlier times act first on the state vector.

\subsection{Many-body Schrödinger equation}\label{sec:manybody_schrodinger_equation}

Up to now, we have mostly described the evolution of a single particle in a potential describing the time-dependent Schrödinger equation~\eqref{time-dependent_Schrodinger_equation}.

In realistic situations, quantum systems often involve many interacting particles.
For instance, electrons in a material evolve under both external fields and their mutual Coulomb interactions.
We therefore extend the description to a nonrelativistic many-body system including electrons, nuclei, and their interactions.

To describe this larger ensemble, we generalize our single particle state $\ket{\psi(t)}$ to a many-body state $\ket{\Psi(t)}$, an element of a larger Hilbert space constructed by the tensor product of individual particle spaces:

\begin{equation}
    \ket{\Psi(t)}\in \mathbb{H}_1\otimes\mathbb{H}_2\otimes \cdots\otimes\mathbb{H}_N=\mathbb{H}.
    \label{many-body_state_vector}
\end{equation}

For identical fermions, the physical many-body states belong to the antisymmetric subspace of $\mathbb{H}$.

For example, in a two-particle system, the total Hilbert space is $\mathbb{H}=\mathbb{H}_1\otimes\mathbb{H}_2$.
It is worth noting that not every state $\ket{\Psi}$ can be factored as  $\ket{\psi_1} \otimes \ket{\psi_2}$, because many physically relevant states are entangled.
This means that their correlations cannot be described by individual particle states alone. In the coordinate representation, we express the wavefunction as:

\begin{equation}
    \Psi(x_1,x_2,\cdots,x_N,t)=\braket{x_1,x_2,\cdots,x_N|\Psi(t)},
    \label{many-body_wavefunction}
\end{equation}

where each $x_i$ includes both spatial and spin degrees of freedom.

The dynamics are governed by a many-body hamiltonian operator $\hat{H}$ and the time evolution is still described by the Schrödinger equation~\eqref{time-dependent_Schrodinger_equation}.

We work in Hartree atomic units unless stated otherwise.
In this unit system, $\hbar=1$, $m_\mathrm{e}=1$, $e=1$, and $4\pi\varepsilon_0=1$.
As a result, energies are measured in Hartree and lengths in the Bohr radius, and the nuclear masses $M_I$ are also given in units of the electron mass.

We stipulate $i$ labels the electrons and $I$ labels nuclei.
Subsequently, we explicitly express each physical contribution to the many-body hamiltonian as a separate operator~\cite{sholl2022density}:

\begin{align}
\text{Electron kinetic energy:}\qquad & \hat{T}_\mathrm{e} = -\frac{1}{2}\sum_i\nabla_i^2
\label{electrons_kinetic} \\
\text{Electron--nucleus Coulomb attraction:}\qquad & \hat{V}_\mathrm{eN}=-\sum_{i,I}\frac{Z_I}{|\vec{r}_i-\vec{R}_I|}
\label{electrons_nucleus_Coulomb} \\
\text{Electron--electron Coulomb repulsion:}\qquad & \hat{V}_\mathrm{ee}=\sum_{i<j}\frac{1}{|\vec{r}_i-\vec{r}_j|}
\label{electrons_Coulomb} \\
\text{Nuclear kinetic energy:}\qquad & \hat{T}_\mathrm{N} = -\sum_I\frac{1}{2M_I}\nabla_I^2
\label{nucleus_kinetic} \\
\text{Nucleus--nucleus Coulomb repulsion:}\qquad & \hat{V}_\mathrm{NN} = \sum_{I<J}\frac{Z_I\,Z_J}{|\vec{R}_I-\vec{R}_J|}
\label{nucleus_interaction}
\end{align}

Summing all these terms, we arrive at the full many-body hamiltonian:

\begin{equation}
    \hat{H}=-\frac{1}{2}\sum_i\nabla_i^2
    -\sum_{i,I}\frac{Z_I}{|\vec{r}_i-\vec{R}_I|}
    +\sum_{i<j}\frac{1}{|\vec{r}_i-\vec{r}_j|}
    -\sum_I\frac{\nabla_I^2}{2M_I}
    +\sum_{I<J}\frac{Z_I\,Z_J}{|\vec{R}_I-\vec{R}_J|}    
    \label{full_many-body_hamiltonian}
\end{equation}

For a given nuclear configuration $\{\vec{R}_I\}$, we regard the hamiltonian as $\hat{H}(\{\vec{r}_i\};\{\vec{R}_I\})$, where the nuclear coordinates enter as external parameters.

Considering the parameters in this hamiltonian, we observe that the many-body wavefunctions for each state $\lambda$ depend explicitly on the $3N$ spatial coordinates of the electrons and their spin degrees of freedom $\sigma_i$.
For the fixed nuclear positions, the stationary electronic states satisfy the eigenvalue equation:

\begin{equation}
    \hat{H}\Psi_\lambda(x_1,x_2,\cdots,x_N)
    = E_\lambda\Psi_\lambda(x_1,x_2,\cdots,x_N)
    \label{many-body_hamiltonian_argument}
\end{equation}

where $N$ denotes the number of electrons, and $x_i\coloneqq(\vec{r}_i,\sigma_i)$.

In practice, due to the significantly greater mass of nuclei compared to electrons, we commonly adopt the clamped-nuclei approximation.
For fixed nuclear positions, the nucleus--nucleus repulsion contributes an additive constant given by $\hat{V}_\mathrm{NN}(\{\vec{R}_I\})$.
It is given by $\hat{V}_\mathrm{NN}(\{\vec{R}_I\})$:

\begin{equation}
\begin{aligned}
\hat{H}
&=-\frac{1}{2}\sum_i\nabla_i^2
+\sum_{i<j}\frac{1}{|\vec{r}_i-\vec{r}_j|}
+\sum_i v_\mathrm{ext}(\hat{\vec{r}}_i)+\hat{V}_\mathrm{NN}(\{\vec{R}_I\}) \\
&=-\frac{1}{2}\sum_i\nabla_i^2
+\sum_{i<j}\frac{1}{|\vec{r}_i-\vec{r}_j|}
+\sum_i v_\mathrm{ext}(\hat{\vec{r}}_i)+E_\mathrm{NN}
\end{aligned}
    \label{atomic_many-body_hamiltonian}
\end{equation}

where $E_\mathrm{NN}\coloneqq \hat{V}_\mathrm{NN}(\{\vec{R}_I\})$.

At this stage, it is convenient to collect all one-body terms acting on the electrons into an external potential.
We define the external potential as:

\begin{equation}
    v_\mathrm{ext}(\vec{r}\,)\coloneqq -\sum_{I}\frac{Z_I}{|\vec{r}-\vec{R}_I|}
\label{one-body_Electron--nucleus}
\end{equation}

For fixed nuclear positions $\{\vec{R}_I\}$, the Electron--nucleus Coulomb attraction term $\hat{V}_\mathrm{eN}$ can be rewritten in the one-body form:

\begin{equation}
    \hat{V}_\mathrm{eN}=\sum_i v_\mathrm{ext}(\hat{\vec{r}}_i)
\label{Electron--nucleus_one-body_form}
\end{equation}

In what follows, we denote the corresponding operator by $\hat{V}_\mathrm{ext}=\sum_i v_\mathrm{ext}(\hat{\vec{r}}_i)$.

More generally, $v_\mathrm{ext}(\vec{r}\,)$ may also include any additional applied one-body fields, so that all system-specific information enters through $v_\mathrm{ext}$.

After truncating each one-particle space to a finite basis of size $d$, the many-body Hilbert space dimension scales as:

\begin{equation}
    \dim(\mathbb{H})\sim d^{N}
    \label{exponential_growth}
\end{equation}

This complexity, known as the "curse of dimensionality," motivates powerful approximate methods such as Hartree--Fock and Density Functional Theory, which we will explore in later sections.

When electron interactions are completely disregarded, the problem simplifies to $N$ independent single-electron problems.
If we further ignore fermionic antisymmetry, the many-body wavefunction reduces to a simple product of single-particle wavefunctions:

\begin{equation}
    \Psi(x_1,x_2,\cdots,x_N)=\psi_{n_1}(x_1)\psi_{n_2}(x_2)\cdots\psi_{n_N}(x_N)
    \label{independent_body_function}
\end{equation}

where $\lambda=\{n_1,n_2,\cdots,n_N\}$ labels the states.

In the coordinate representation, we can represent the antisymmetric wavefunction as a Slater determinant:

\begin{equation}
    \Psi = \frac{1}{\sqrt{N!}}
    \begin{vmatrix}
    \psi_1(\vec{r}_1,\sigma_1) & \psi_1(\vec{r}_2,\sigma_2) & \cdots & \psi_1(\vec{r}_N,\sigma_N)\\
    \psi_2(\vec{r}_1,\sigma_1) & \psi_2(\vec{r}_2,\sigma_2) & \cdots & \psi_2(\vec{r}_N,\sigma_N)\\
    \vdots & \vdots & \ddots & \vdots\\
    \psi_N(\vec{r}_1,\sigma_1) & \psi_N(\vec{r}_2,\sigma_2) & \cdots & \psi_N(\vec{r}_N,\sigma_N)
    \end{vmatrix}
    \label{slater_determinant}
\end{equation}

Finally, we can describe the full time-evolution of the many-body wavefunction in coordinate space by the time-dependent Schrödinger equation~\eqref{time-dependent_Schrodinger_equation}:

\begin{equation}
    i\frac{\partial}{\partial t}\Psi(x_1,x_2,\cdots,x_N,t)
    = \hat{H}\,\Psi(x_1,x_2,\cdots,x_N,t)
    \label{tdse_manybody_coord}
\end{equation}

\subsection{From Schrödinger picture to Heisenberg picture}

Up to now, we have adopted the Schrödinger picture to describe the time evolution of quantum systems. In this picture, states carry all the time dependence, while operators remain fixed. Specifically, the quantum state $\ket{\psi(t)}$ evolves in time according to the Schrödinger equation~\eqref{time-dependent_Schrodinger_equation}.

For a given observable represented by a Hermitian (self-adjoint) operator $\hat{\Omega}$, its expectation value is calculated as:

\begin{equation}
    \braket{\hat{\Omega}} = \braket{\psi(t)|\hat{\Omega}|\psi(t)}
    \label{expectation_Hermitian}
\end{equation}

In the standard formulation of quantum mechanics, observables represent measurable physical quantities, so their expectation values are real.
This is why observables are taken to be Hermitian operators, which ensures real eigenvalues and guarantees that $\braket{\hat{\Omega}}\in\mathbb{R}$.

To set up the transformation, we return to the Schrödinger picture.
Recall \eqref{state_time_evolution} and the definition of the time-evolution operator in \eqref{time_evolution_operator}.
With $\hat{U}(t,t_0)$, the two pictures are related as follows.

In the Heisenberg picture, the state at the reference time $t_0$ is taken to be time-independent:

\begin{equation}
    \ket{\psi_\mathrm{H}}=\ket{\psi(t_0)}
    \label{heisenberg_state_definition}
\end{equation}

We keep the state fixed and shift the time dependence to the operators.
For any Schrödinger picture operator $\hat{\Omega}$, we can define its Heisenberg counterpart $\hat{\Omega}_\mathrm{H}(t)$ as:

\begin{equation}
    \hat\Omega_\mathrm{H}(t)
    =\hat{U}^\dagger(t,t_0)\,\hat{\Omega}\,\hat{U}(t,t_0)
    =\mathrm{e}^{\frac{\mathrm{i}}{\hbar}\hat{H}(t-t_0)}\,\hat{\Omega}\,\mathrm{e}^{-\frac{\mathrm{i}}{\hbar}\hat{H}(t-t_0)}
    \label{heisenberg_operator_definition}
\end{equation}

This definition transfers the time dependence from the state to the operator.

With these definitions, the expectation value is unchanged from Schrödinger to the Heisenberg picture.
Applying the expression of time-evolution operator\eqref{state_time_evolution},
the following relation demonstrates the equivalence of the two pictures:

\begin{equation}
\begin{aligned}
    \braket{\hat{\Omega}}(t)&=\bra{\psi(t)}\hat{\Omega}\ket{\psi(t)}\\
    &=\bra{\psi(t_0)}\hat{U}^\dagger(t,t_0)\,\hat{\Omega}\,\hat{U}(t,t_0)\ket{\psi(t_0)} \\
    &=\bra{\psi_\mathrm{H}}\hat{\Omega}_\mathrm{H}(t)\ket{\psi_\mathrm{H}}
\end{aligned}
\label{equivalence_schrodinger_heisenberg}
\end{equation}

For a time-independent hamiltonian and an operator without explicit time dependence in the Schrödinger picture, differentiating \eqref{heisenberg_operator_definition} gives the Heisenberg equation of motion~\cite{shankar2012principles}:

\begin{equation}
    \frac{\mathrm{d}}{\mathrm{d}t}\hat{\Omega}_\mathrm{H}(t)
    =\frac{\mathrm{i}}{\hbar}\left[\hat{H},\hat{\Omega}_\mathrm{H}(t)\right]
    \label{heisenberg_equation_of_motion}
\end{equation}

This form is particularly convenient for discussing conserved quantities and symmetries, since it expresses the dynamics directly at the operator level.

\subsection{From Heisenberg picture to the continuity equation}

Having seen that any local one-body observable can be written as an integral over a single function, we now introduce that central quantity. The one-body density contains all the information needed to compute one-particle expectation values and serves as the fundamental variable in the density functional theory~\cite{sholl2022density}. In what follows, we review its precise definition.

\begin{equation}
n(\vec{r}\,)
= \bra{\psi}\,\hat{n}(\vec{r}\,)\ket{\psi}
= \bra{\psi}\sum_i\delta(\vec{r} - \hat{\vec{r}}_i)\ket{\psi}
\label{one-body_density}
\end{equation}

gives the electron density at point $\vec{r}$.
Physically, $n(\vec{r}\,)\mathrm{d}^3r$ is the expected number of electrons in the volume element $\mathrm{d}^3r$ around $\vec{r}$.
In density functional theory, $n(\vec{r}\,)$ serves as the fundamental variable replacing the full many-body wavefunction.  

It can be shown that the ground state density $n(\vec{r}\,)$ uniquely fixes the external potential, which is up to an additive constant, and hence all ground state observables can be written as functionals of $n(\vec{r}\,)$.
This dramatic reduction comes from a 3$N$-dimensional wavefunction to a three-dimensional density, which lies at the heart of density functional theory, making formerly intractable many-body problems computationally feasible.

The time-dependent density-functional theory relies on the continuity equation in the Heisenberg picture.
We first define the particle density operator in the Schrödinger-picture as:

\begin{equation}
    \hat{n}(\vec{r}\,)
    = \sum_i \delta(\vec{r}-\hat{\vec{r}}_i)
    \label{Schrodinger-picture_density_operator}
\end{equation}

and its corresponding Heisenberg-picture counterpart is defined by the unitary time evolution as:

\begin{equation}
    \hat{n}_\mathrm{H}(\vec{r},t)
    = \hat U^\dagger(t)\,\hat{n}(\vec{r}\,)\,\hat{U}(t)
    \label{Heisenberg-picture_density_operator}
\end{equation}

Its time derivative follows from the Heisenberg equation of motion,

\begin{equation}
    \frac{\partial}{\partial t}\hat n_\mathrm{H}(\vec{r},t)
    = \frac{\mathrm{i}}{\hbar}\left[\hat{H},\hat n_\mathrm{H}(\vec{r},t)\right]
\label{density_time_derivative}
\end{equation}

Next, split the hamiltonian into kinetic and potential parts,

\begin{equation}
\hat{H} = \hat{T} + \hat{V}_\mathrm{ext} + \hat{V}_\mathrm{ee}
\label{splitted_hamiltonian}
\end{equation}

One shows that both $\hat{V}_\mathrm{ext}$ and $\hat{V}_\mathrm{ee}$ commute with $\hat{n}(\vec{r}\,)$:

\begin{equation}
    \left[\hat{V}_\mathrm{ext}+\hat{V}_\mathrm{ee},\,\hat n_\mathrm{H}(\vec{r},t)\right] = 0
\label{commuting_potential_density}
\end{equation}

They are diagonal in the coordinate basis, so only the kinetic term contributes:

\begin{equation}
    \frac{\partial}{\partial t}\hat{n}_\mathrm{H}
    = \frac{\mathrm{i}}{\hbar}\left[\hat{T},\hat{n}_\mathrm{H}\right]
\label{kinetic_term_contribution}
\end{equation}

The Heisenberg-picture current operator can now be introduced:

\begin{equation}
    \hat{\vec{j}}_\mathrm{H}(\vec{r},t)
    = \frac{1}{2m_\mathrm{e}}\sum_i\left[\hat{\vec{p}}_i\,\delta(\vec{r}-\hat{\vec{r}}_i)+\delta(\vec{r}-\hat{\vec{r}}_i)\,\hat{\vec{p}}_i\right]_\mathrm{H}
\label{heisenberg-picture_current_operator}
\end{equation}

where $\hat{\vec{p}}_i$ is the momentum operator of particle $i$. A direct commutator calculation then yields

\begin{equation}
    \frac{\mathrm{i}}{\hbar}\left[\hat{T},\hat n_\mathrm{H}(\vec{r},t)\right]
    = -\nabla\cdot\hat{\vec{j}}_\mathrm{H}(\vec{r},t)
\label{direct_commutator}
\end{equation}

Putting these results into equation~\eqref{density_time_derivative} gives the operator-level continuity equation:

\begin{equation}
\frac{\partial}{\partial t}\,\hat{n}_\mathrm{H}(\vec{r},t)+\nabla\cdot\hat{\vec j}_\mathrm{H}(\vec{r},t)=0
\label{continuity_operator}
\end{equation}

Taking expectation values in any Heisenberg-picture state $\ket{\Psi_\mathrm{H}}$ then yields the familiar continuity equation for the physical density $n(\vec{r},t)=\bra{\Psi_\mathrm{H}}\hat{n}_\mathrm{H}(\vec{r},t)\ket{\Psi_\mathrm{H}}$
and current $\vec{j}(\vec{r},t)=\bra{\Psi_\mathrm{H}}\hat{\vec{j}}_\mathrm{H}(\vec{r},t)\ket{\Psi_\mathrm{H}}$:

\begin{equation}
    \frac{\partial}{\partial t}\,n(\vec{r},t)+\nabla\cdot\vec{j}(\vec{r},t)=0.
\label{continuity_expectation}
\end{equation}

This exact conservation law shows that once the initial density $n(\vec{r},0)$ and the time-dependent external potential $v_\mathrm{ext}(\vec{r},t)$ are specified, the density and current uniquely evolve according to equations \eqref{continuity_operator} and \eqref{continuity_expectation}. This observation is the cornerstone of time-dependent density functional theory, where one seeks to replace the full many-body wavefunction by the basic variable $n(\vec{r},t)$ together with suitable current functionals.

\newpage
\section{Continue to consider the many-body problem}

In fact, a many-body wavefunction explicitly depends on all particle coordinates, making it practically impossible to calculate and store exactly due to the exponential increase in complexity with particle number.

Nevertheless, what we ultimately aim to describe are measurable properties.
These include observables like position, momentum, energy, or spin.
We can extract them from the wavefunction through expectation values:

\begin{equation}
    \braket{\hat{\Omega}} = \bra{\Psi}\hat{\Omega}\ket{\Psi}
    \label{obvious}
\end{equation}

\subsection{An introduction to grand canonical ensemble}

Before proceeding further, it is essential to introduce the grand canonical ensemble, as it naturally accommodates quantum many-body systems exchanging particles and energy with external reservoirs. This treatment is particularly crucial in Density Functional Theory calculations for realistic materials, where fluctuations in particle number and thermal effects are common.

In the grand canonical ensemble, the expectation value of any observable operator $\hat{\Omega}$ is computed as follows:

\begin{equation}
    \braket{\hat{\Omega}} 
    = \frac{1}{\mathcal{Z}}\sum_{\alpha}\mathrm{e}^{-\beta(E_{\alpha}-\mu N_{\alpha})}\bra{\Psi_{\alpha}}\hat{\Omega}\ket{\Psi_{\alpha}}
\label{grand_canonical}
\end{equation}

where the summation runs over all quantum states labeled by $\alpha$. Here, $\Psi_{\alpha}$ represents the many-body quantum states of the system, characterized by their energies $E_{\alpha}$ and particle numbers $N_{\alpha}$. The inverse temperature $\beta$ is defined as $\beta = 1/(k_B T)$, with $T$ being the temperature and $k_B$ the Boltzmann constant. The chemical potential $\mu$ controls particle exchange between the system and its reservoir. The partition function $\mathcal{Z}$ serves as a normalization factor and is defined as:

\begin{equation}
    \mathcal{Z} = \sum_{\alpha} \mathrm{e}^{-\beta(E_{\alpha}-\mu N_{\alpha})}
\label{partition_function}
\end{equation}

In quantum many-body theory and calculation, employing the grand canonical ensemble allows systematic inclusion of particle number fluctuations and thermal equilibrium effects, providing a robust and realistic statistical-mechanical description essential for accurate modeling of complex quantum materials.

In what follows, we mainly focus on the ground state setting: zero temperature and fix particle number; while the grand-canonical form is noted for completeness and later extensions.

\subsection{From wavefunction to practical functionals}

Let us stay at zero temperature and fixed particle number $N$.
Consider the operator for the measurement $\sum_{i,j,\cdots}\hat\Omega\left(x_i,x_j,\cdots\right)$,
and the ground-state $N$-body wavefunction $\Psi(x_1,x_2,\cdots,x_N)$.
By inserting resolutions of the identity in the coordinate basis for all particles, $I=\int \mathrm{d}x\,\ket{x}\bra{x}$~\cite{shankar2017quantum},
we can represent the expectation value as:

\begin{equation}
\begin{aligned}
    \braket{\hat\Omega} 
    &= \bra{\Psi}\hat\Omega\ket{\Psi} \\
    &= \iint\cdots\int \mathrm{d}x_1\mathrm{d}x_2\cdots\mathrm{d}x_N\,\Psi^*(x_1,x_2,\cdots,x_N)\sum_{i,j,\cdots}\hat\Omega\left(x_i,x_j,\cdots\right)\Psi(x_1,x_2,\cdots,x_N)
\end{aligned}
\label{observables_N-body}
\end{equation}

Therefore, we may regard the expectation value of the observable as a functional of the many-body wavefunction $\Psi$, and write

\begin{equation}
\Omega[\Psi] = \bra{\Psi}\hat{\Omega}\ket{\Psi}
\label{observables_functional}
\end{equation}

here, the square brackets $[\Psi]$ (rather than parentheses) emphasize that $\Omega$ is a functional, it is a mapping from the entire wavefunction $\Psi$ to a scalar.

A functional simply assigns a number to a function. In our case of equation~\eqref{observables_N-body}, its form is a known integral. However, evaluating it requires the exact many-body wavefunction, which we generally cannot compute or store. Moreover, integration acts as an averaging operation that smooths out microscopic fluctuations, so only the coarse-grained features of the integrand contribute to the result.

Consequently, we can discard irrelevant details of the many-body wavefunction and work with simplified approximations tailored to specific observables. Normally, we use approximate wavefunctions: methods such as Hartree--Fock, configuration interaction, and quantum Monte Carlo exploit this idea by retaining the dominant components of the wavefunction while approximating or sampling the rest.

A more radical question is whether we need to work with explicit wavefunctions at all, or if the expectation value in equation~\eqref{observables_N-body} can be reformulated entirely in terms of other, more tractable quantities.

In the case of this approximation, for a given hamiltonian $\bra{\Psi}\hat{H}\ket{\Psi}$, we can regard it as depending on the form of the kinetic energy operator $\bra{\Psi}\hat{T}\ket{\Psi}$, external potential operator $\bra{\Psi}\hat{V}_\mathrm{ext}\ket{\Psi}$, and the interaction operator $\bra{\Psi}\hat{V}_\mathrm{int}\ket{\Psi}$.

To specify the quantum dynamics and interactions of our system, we begin by defining its hamiltonian. The hamiltonian encodes all system-specific information:

\begin{equation}
    \hat{H}
    = -\frac{1}{2}\sum_i\nabla_i^2
    + \sum_i v_{\mathrm{ext}}(\hat{\vec{r}}_i)
    + \sum_{i<j}\frac{1}{|\vec{r}_i - \vec{r}_j|}
\label{hamiltonian}
\end{equation}

In the present electronic many-body problem within the Born-Oppenheimer approximation, 
the nuclear coordinates are clamped, and the nuclear-nuclear repulsion becomes a negligible constant. 
We can identify the interaction operator as the electron--electron Coulomb repulsion~\eqref{electrons_Coulomb},
and the external potential acting on the electrons is the attractive Electron--nucleus interaction, which can be written as a sum of one-body terms~\eqref{Electron--nucleus_one-body_form}:

\begin{equation}
\begin{aligned}
    \hat{V}_\mathrm{int} &\coloneqq \hat{V}_{\mathrm{ee}}
    = \sum_{i<j}\frac{1}{\left|\vec{r}_i-\vec{r}_j\right|} \\
    \hat{V}_\mathrm{ext} &\coloneqq \hat{V}_{\mathrm{eN}}
    =\sum_i v_\mathrm{ext}(\hat{\vec{r}}_i)
\end{aligned}
\label{reduced_operator_definition}
\end{equation}

Using the expression for the electron kinetic energy operator in equation~\eqref{electrons_kinetic}, we arrive at:

\begin{equation}
\begin{aligned}
    \bra{\Psi}\hat{H}\ket{\Psi} &= \bra{\Psi}\hat{T}\ket{\Psi} + \bra{\Psi}\hat{V}_\mathrm{ext}\ket{\Psi} + \bra{\Psi}\hat{V}_\mathrm{int}\ket{\Psi} \\
    &= \bra{\Psi}-\frac{1}{2}\sum_i\nabla_i^2\ket{\Psi}
    + \bra{\Psi}\sum_i v_{\mathrm{ext}}(\vec{r}_i)\ket{\Psi}
    + \bra{\Psi}\sum_{i<j}\frac{1}{|\vec{r}_i-\vec{r}_j|}\ket{\Psi}
\end{aligned}
\label{approx}
\end{equation}

Having treated both the kinetic energy operator and the interaction term as fixed, specifying the external potential $v_\mathrm{ext}(\vec{r}\,)$ uniquely determines the hamiltonian $\hat{H}$.
For any normalized many-body state $\ket{\Psi}$, we define the energy expectation value as:

\begin{equation}
    E \coloneqq \bra{\Psi}\hat{H}\ket{\Psi}
\label{energy_expectation_value_definition}
\end{equation}

When $\ket{\Psi}$ is chosen to be an eigenstate of $\hat{H}$, denoted by $\ket{\Psi_n}$,
the corresponding eigenvalue $E_n$ and eigenstate are determined by the Schrödinger equation:

\begin{equation}
    \hat{H}\ket{\Psi_n}=E_n\ket{\Psi_n}
\label{schrodinger_eigenvalue_equation}
\end{equation}

Accordingly, one may view the spectrum and the eigenstates as depending on the external potential through the hamiltonian:

\begin{equation}
    v_\mathrm{ext}(\vec{r}\,) \longmapsto \left\{\ket{\Psi_n\left[v_\mathrm{ext}(\vec{r}\,)\right]}, E_n\left[v_\mathrm{ext}(\vec{r}\,)\right]\right\}_{n}.
\label{spectrum_mapping_from_external_potential}
\end{equation}

where $E_n\left[v_\mathrm{ext}\right]$ denotes the energy eigenvalue associated with the stationary state $\ket{\Psi_n\left[v_\mathrm{ext}\right]}$, namely:

\begin{equation}
    E_n\left[v_\mathrm{ext}(\vec{r}\,)\right] \coloneqq
    \bra{\Psi_n\left[v_\mathrm{ext}(\vec{r}\,)\right]}\hat{H}\ket{\Psi_n\left[v_\mathrm{ext}(\vec{r}\,)\right]}.
\label{eigenenergy_as_expectation_value}
\end{equation}

The grand-canonical ensemble admits a compact operator formulation in terms of a trace over the many-body Hilbert space.
Invoking the cyclic invariance of the trace, we obtain:

\begin{equation}
    \left\langle \hat{\Omega}\right\rangle
    = \frac{1}{\mathcal{Z}}\,\operatorname{Tr}\,\left[\mathrm{e}^{-\beta\left(\hat{H}-\mu \hat{N}\right)}\,\hat{\Omega}\right],
\label{grand_canonical_expectation_trace}
\end{equation}

with the grand-canonical partition function:

\begin{equation}
    \mathcal{Z}
    =\sum_{\alpha}\mathrm{e}^{-\beta\left(E_{\alpha}-\mu N_{\alpha}\right)} 
    =\operatorname{Tr}\,\left[\mathrm{e}^{-\beta\left(\hat{H}-\mu \hat{N}\right)}\right].
\label{grand_partition_function_trace}
\end{equation}

Note that the sum over states in equation~\eqref{grand_canonical} is nothing but a trace over the many-body Hilbert space.  By using the cyclic invariance of the trace, we can therefore recast both the expectation value and the partition function in the compact operator form:

\begin{equation}
    \braket{\hat\Omega}
    = \frac{1}{\mathcal{Z}}\sum_\alpha \mathrm{e}^{-\beta(E_\alpha-\mu N_\alpha)}\bra{\Psi_\alpha}\hat\Omega\ket{\Psi_\alpha} 
\label{grand_canonical_trace}
\end{equation}

Equivalently, by expanding the trace in the eigenbasis of $\hat{H}$, equation~\eqref{grand_canonical_expectation_trace} reduces to the sum representation in equation~\eqref{grand_canonical_trace}.

In principle, all physical observables derive from the many-body Schrödinger equation equation~\eqref{tdse_manybody_coord}, yet the exponential growth of the Hilbert-space dimension renders direct diagonalization intractable for realistic systems.

If the kinetic energy operator and Coulomb interaction are fixed, the ground state total energy becomes a functional of the external potential we introduced equation~\eqref{spectrum_mapping_from_external_potential}.

A central challenge is that evaluating the grand-canonical expectation in equation~\eqref{grand_canonical_trace} remains highly nontrivial, as the trace involves high-dimensional integrals and noncommuting operators.

Our aim is to express the expectation values—which are, in principle, highly complex functionals—in terms of a single simple function, so that practical approximations become possible.

Next, recall the general expression for an observable in a many-body system: equation~\eqref{observables_N-body}. If the observable is a local one-body operator, we have

\begin{equation}
\begin{aligned}
    \braket{\hat\Omega_1}
    &= \bra{\Psi}\hat\Omega_1\ket{\Psi} \\
    &= \iint\cdots\int \mathrm{d}x_1\mathrm{d}x_2\cdots\mathrm{d}x_N\,\Psi^*(x_1,x_2,\cdots,x_N)\sum_{i}\hat\Omega_1(x_i)\Psi(x_1,x_2,\cdots,x_N) \\
    &= \int\mathrm{d}x_1\Omega_1(x_1)N\int\mathrm{d}x_2\cdots\mathrm{d}x_N\,\Psi^*(x_1,x_2,\cdots,x_N)\Psi(x_1,x_2,\cdots,x_N)
\end{aligned}
\label{observables_one-body}
\end{equation}

We can find that this integral naturally factors into two components: the one-body operator term

\begin{equation}
\int\mathrm{d}x_1\,\Omega_1(x_1)N
\label{one-body_operator}
\end{equation}

and the one-body density

\begin{equation}
n(x_1)=N\int\mathrm{d}x_2\cdots\mathrm{d}x_N\Psi^*(x_1,x_2,\cdots,x_N)\Psi(x_1,x_2,\cdots,x_N),
\label{one-body_density}
\end{equation}

here $x$ denotes the one-particle coordinate.
If $x$ refers to the spatial coordinate only, we write $x=\vec{r}$ and denote the usual spatial density as $n(\vec{r}\,)$.
More generally, in many-body notation $x$ denotes a combined space-spin coordinate, and we write $x=(\vec{r},\sigma)$.
In this case, $n(x)=n(\vec{r},\sigma)$ is the spin-resolved one-body density.

In many condensed matter physics applications, we work with the spin-summed density.
To recover the spin-summed spatial density, we write a discrete sum over the spin index:

\begin{equation}
    n(\vec{r}\,)=\sum_{\sigma} n(\vec{r},\sigma)
\label{sum_spatial_density}
\end{equation}

or use an integral notation for the spin index,

\begin{equation}
    n(\vec{r}\,)=\int\mathrm{d}\sigma\,n(\vec{r},\sigma)
\label{integral_spatial_density}
\end{equation}

Both notations express the same idea: the spatial density is obtained by summing over the spin degree of freedom.

%%

Throughout this chapter, for simplicity, when we write $\int\mathrm{d}x$, it means $\sum_{\sigma}\int\mathrm{d}\vec{r}$.
For spin-independent external potentials, we write $v_\mathrm{ext}(x)=v_\mathrm{ext}(\vec{r}\,)$.

The density is also constrained by particle number conservation.
For a spin-resolved density $n(x)$, we define the particle number functional as:

\begin{equation}
    N[n]\coloneqq\int\mathrm{d}x\,n(x)
    \label{particle_number_functional}
\end{equation}

and in the ground-state setting with fixed particle number we require:

\begin{equation}
    N[n]=N
    \label{particle_number_constraint_density}
\end{equation}

% Equivalently, for the spin-summed spatial density, the same condition reads
% $\int \mathrm{d}\vec{r}\,n(\vec{r}\,)=N$.
Equivalently, for the spin-summed spatial density, the same condition takes the form $\int \mathrm{d}\vec{r}\,n(\vec{r}\,)=N$.
This constraint will be enforced explicitly when we later vary an energy functional with respect to $n$.

We also note that not every non-negative function is an admissible density.
In general, a candidate $n(x)$ must be compatible with an antisymmetric $N$-body wavefunction and the chosen external potential.
In what follows, we keep these representability requirements implicit,
and we work within the set of admissible densities, and equation~\eqref{particle_number_constraint_density} provides the particle number constraint.

%%

The expectation value reduces to:

\begin{equation}
\braket{\hat\Omega_1}=\int\mathrm{d}x_1\,\Omega_1(x_1)n(x_1)
\label{observables_one-body_density}
\end{equation}

Thus, rather than computing the full many-body integral, we need only determine the one-body density $n(x_1)$.

Next, consider the electron--electron Coulomb interaction energy:

\begin{equation}
\begin{aligned}
    \hat{V}_\mathrm{ee}
    &= \iint\cdots\int \mathrm{d}x_1\mathrm{d}x_2\cdots\mathrm{d}x_N\,\Psi^*(x_1,x_2,\cdots,x_N)\sum_{i,j>i}\frac{1}{|\vec{r}_i-\vec{r}_j|}\Psi(x_1,x_2,\cdots,x_N) \\
    &= \int\mathrm{d}x_1\mathrm{d}x_2\,\frac{1}{2|\vec{r}_1-\vec{r}_2|}N(N-1)\int\mathrm{d}x_3\cdots\mathrm{d}x_N\,\Psi^*(x_1,x_2,\cdots,x_N)\Psi(x_1,x_2,\cdots,x_N)
\end{aligned}
\label{coulomb_interaction_energy}
\end{equation}

here, the two-body density naturally appears:

\begin{equation}
n^{(2)}(x_1,x_2)=N(N-1)\int\mathrm{d}x_3\cdots\mathrm{d}x_N\,\Psi^*(x_1,x_2,\cdots,x_N)\Psi(x_1,x_2,\cdots,x_N)
\label{two-body_density}
\end{equation}

So that the expectation value of the Coulomb interaction energy reduces to:

\begin{equation}
    \braket{\hat{V}_\mathrm{ee}}=\frac{1}{2}\int\mathrm{d}x_1\mathrm{d}x_2\,
    \frac{n^{(2)}(x_1,x_2)}{|\vec{r}_1-\vec{r}_2|}
\label{observables_two-body_density}
\end{equation}

Similarly, the kinetic energy expectation value is

\begin{equation}
\begin{aligned}
    T&= -\iint\cdots\int \mathrm{d}x_1\mathrm{d}x_2\cdots\mathrm{d}x_N\,\Psi^*(x_1,x_2,\cdots,x_N)\sum_{i}\frac{\nabla_i^2}{2}\Psi(x_1,x_2,\cdots,x_N) \\
    &= \lim_{x'_1\to x_1}\left( -\int\mathrm{d}x_1\left[\frac{\nabla_i^2}{2}N\int\cdots\int\mathrm{d}x_2\cdots\mathrm{d}x_N\,\Psi^*(x_1,x_2,\cdots,x_N)\Psi(x'_1,x_2,\cdots,x_N) \right]\right)
\end{aligned}
\label{kinetic_energy}
\end{equation}

We can also separate this integral via the matrix of density:

\begin{equation}
\rho(x_1,x'_1)
=N\int\cdots\int\mathrm{d}x_2\cdots\mathrm{d}x_N\,\Psi^*(x_1,x_2,\cdots,x_N)\Psi(x'_1,x_2,\cdots,x_N) 
\label{density_matrix}
\end{equation}

and get the simplified expectation value of the kinetic energy operator:

\begin{equation}
T= \lim_{x'_1\to x_1}\left( -\int\mathrm{d}x_1\left[\frac{\nabla_i^2}{2}\rho(x_1,x'_1) \right]\right)
\label{kinetic_energy_density_matrix}
\end{equation}

We begin by insisting on a single functional variable $Q$ such that every observable of interest $\hat\Omega_i$ can be written in the form $\hat\Omega_i[Q]$.
Having identified $Q$, we then derive the explicit mappings $\hat\Omega_i[Q]$ for each target observable.
Finally, we develop a practical algorithm or an approximation scheme to compute $Q$ itself, thereby rendering all observables $\hat\Omega_i[Q]$ tractable.

Given a time-dependent many-body wavefunction: $\Psi(x_1,x_2,\cdots,x_N; t)$. 
We denote the corresponding ground state ($g\coloneqq 0$) many-body wavefunction as 
$\Psi_g(x_1,x_2,\cdots,x_N; t)$.
We can also denote the excited states by an index $\alpha$ ($\alpha\geq1$), 
as $\Psi_{\alpha}(x_1,x_2,\cdots,x_N; t)$.

Then, we can describe the ground state one-body density:

\begin{equation}
\rho_g(x_1,t)=\int \mathrm{d}x_2\cdots\mathrm{d}x_N\,\Psi_g^*(x_1,x_2,\cdots,x_N;t)\Psi_g(x_1,x_2,\cdots,x_N;t)
\label{ground_one-body_density}
\end{equation}

When this system makes transitions to excited states, the one-body transition quantity is obtained by integrating other coordinates:

\begin{equation}
f_n^\mathrm{eh}(x_1,t)=\int \mathrm{d}x_2\cdots\mathrm{d}x_N\,\Psi_g^*(x_1,x_2,\cdots,x_N;t)\Psi_n(x_1,x_2,\cdots,x_N;t)
\label{transition_one-body}
\end{equation}

Equivalently, the reduced (marginal) integral $f_n^\mathrm{eh}(x_1,t)=\int\Psi_g^*(\vec{x};t)\Psi_n(\vec{x};t)\prod^N_{j=2}\mathrm{d}x_j$ is the one-body transition density from ground state $g$ to the $n$-th excited state.

In the presence of an oscillating electromagnetic field, we introduce the Bohr frequency 
$\omega_{ng}=(E_n-E_g)/\hbar$ (set $\hbar=1$ if desired). The corresponding phase factor associated with the excitation energy is $\mathrm{e}^{-i(E_n-E_g)t}$.
If one separates the trivial time phases so that $\Psi_{g/n}(\vec{x};t)=\Phi_{g/n}(\vec{x})\mathrm{e}^{-iE_{g/n}t/\hbar}$, then the transition density can be written as

\begin{equation}
\begin{aligned}
    & f_n^\mathrm{eh}(x_1,t)\\
    =& \mathrm{e}^{-i(E_n-E_g)t}\int\mathrm{d}x_2\cdots\mathrm{d}x_N\,\Psi_g^*(x_1,x_2,\cdots,x_N;t)\Psi_n(x_1,x_2,\cdots,x_N;t)
\end{aligned}
\label{mod_transition_one-body}
\end{equation}

here, $\int\mathrm{d}x_2\cdots\mathrm{d}x_N\,\Psi_g^*(x_1,x_2,\cdots,x_N;t)\Psi_n(x_1,x_2,\cdots,x_N;t)$ denotes the transition amplitude.

Recall a one-body operator $\hat{\Omega}^{(1)}$ with kernel $\Omega_1(x_1)$,
the one-body density $n(x_1)$,
the one-body density matrix $\rho(x_1,x'_1)$,
and the pair density $n^{(2)}(x_1,x_2)$ (the spatial parts are contained in $x_1,x_2$):

\begin{equation}
\begin{aligned}
    \braket{\hat{\Omega}^{(1)}} &= \int \mathrm{d}x_1\,\Omega_1(x_1)\,n(x_1)\\
    T &= -\frac{1}{2}\int \mathrm{d}x_1\,
    \Big[\nabla_{x'_1}^{2}\,\rho(x_1,x'_1)\Big]_{x'_1=x_1}\\
    \braket{\hat{V}_\mathrm{ee}} &= \frac{1}{2}\int \mathrm{d}x_1\,\mathrm{d}x_2\,
    \frac{n^{(2)}(x_1,x_2)}{|\vec{r}_1-\vec{r}_2|}
\end{aligned}
\label{one-body_operator_with_kernel}
\end{equation}

Hence, a typical energy-like observable can be written as

\begin{equation}
\begin{aligned}
    \braket{\Omega_1}
    &= \int \mathrm{d}x_1\, \Omega_1(x_1)\, n(x_1) \\
    &\quad - \frac{1}{2}\int \mathrm{d}x_1\,
    \Big[\nabla_{x'_1}^{2}\,\rho(x_1,x'_1)\Big]_{x'_1=x_1} \\
    &\quad + \frac{1}{2}\int \mathrm{d}x_1\,\mathrm{d}x_2\,
    \frac{n^{(2)}(x_1,x_2)}{|\vec{r}_1-\vec{r}_2|}
\end{aligned}
\label{mod_obs_1}
\end{equation}

% Compact Q -> lead to density functional

Up to now, we do not have closed-form expressions for the objects appearing in equation~\eqref{mod_obs_1}, and evaluating them still requires many-body information beyond practical reach.
This motivates the introduction of a compact descriptor: rather than working with the full wavefunction $\Psi(x_1,\cdots,x_N)$, we seek a simpler variable $Q$ that is nevertheless sufficient to determine the observables of interest.

More precisely, let $\{\hat{\Omega}_i\}_{i=1,2,\cdots}$ denote the operators representing the target physical quantities, and let $\Omega_i[\Psi]$ denote their ground state expectation values regarded as functionals of the wavefunction.
Our goal is to find a single descriptor $Q$ such that, once $Q$ is known, all these observables can be evaluated without explicit reference to the wavefunction $\Psi$:

\begin{equation}
    \Psi \mapsto Q,\quad\Omega_i[\Psi] = \Omega_i[Q],\quad(i=1,2,\cdots)
    \label{descriptor_Q_mapping}
\end{equation}

In other words, $Q$ is chosen to retain exactly the information needed for the set $\{\Omega_i\}$, while discarding irrelevant microscopic details.

In particular, we set $Q \coloneqq n(x)$. In the following, we take the particle density $n(x)$ as the basic variable, as it provides a minimal yet powerful descriptor of the ground state. In this statement, $x$ denotes a combined space-spin coordinate, $x=(\vec{r},\sigma)$, so that we can represent the one-body (spin-resolved) density as $n(x)$:

Firstly, the particle density $n(x)$ yields exactly all local one-body observables. For an operator of the form $\hat{\Omega}^{(1)}=\sum_{j=1}^N \Omega_1(x_j)$, one has:

\begin{equation}
    \braket{\hat{\Omega}^{(1)}}=\int \mathrm{d}x\,\Omega_1(x)\,n(x)
    \label{one-body_observables}
\end{equation}

Secondly, the particle density $n(x)$ is extremely compact compared to the wavefunction $\Psi$.
Moreover, in the case of a non-degenerate ground state, the Hohenberg--Kohn theorem implies a bijective correspondence between the ground state density and the external potential.
As a result, $n(x)$ determines $v_\mathrm{ext}$ up to an additive constant.
This fixes the hamiltonian and thereby fixes the ground state up to an overall phase.
Therefore, all ground state observables may be regarded as density functionals, and we seek $\Omega_i[n]$ rather than $\Omega_i[\Psi]$.

Therefore, we explore the variational route for $n$. Define the energy-like functional:

\begin{equation}
    E[n;v_\mathrm{ext}]=T[n]+E_\mathrm{int}[n]+\int\mathrm{d}x\,v_\mathrm{ext}(x)n(x)
\label{energy-like_functional}
\end{equation}

and obtain the ground state density from
\begin{equation}
    \frac{\delta}{\delta n}\left(E[n;v_\mathrm{ext}] - \mu\,N[n]\right)=0 \ \Rightarrow\ n_g(x)
\label{ground state_density}
\end{equation}

Once $n_g$ is known, all desired observables are evaluated as $\Omega_i[n_g]$; 
for non-local one-body or two-body quantities,
this amounts to adopting controlled approximations for kinetic energy functional $T[n]$ and interaction energy functional $E_\mathrm{int}[n]$ such as the Kohn-Sham framework, which we will introduce later.

\newpage
\section{An introduction to the functional of density}

\subsection{What is the functional?}

A functional is a mapping that takes a function as its input and returns a number (or sometimes another function).

The reason we introduce density functional theory in condensed matter physics research is that solving the full many-body or many-electron Schrödinger equation scales hopelessly with the number of electrons~\cite{sholl2022density}. DFT reformulates it as a variational problem in terms of the three-dimensional electron density 
$n(\vec{r}\,)$, making predictive calculations of structures, band structures, magnetism, and reaction energetics feasible.

For example, in condensed matter physics, it often appears as a map from electron density $n(\vec{r}\,)$ to the total energy $E[n]$ given by an external potential:

\begin{equation}
    E_\mathrm{ext}[n]=\int\mathrm{d}\vec{r}\,n(\vec{r}\,)v_\mathrm{ext}(\vec{r}\,)
\label{functional_energy_potential}
\end{equation}

It also often appears that we use a non-local functional to describe the classical electrostatic term or the Hartree energy:

\begin{equation}
    E_\mathrm{H}[n]=\frac{1}{2}\int\mathrm{d}\vec{r}_i\,\mathrm{d}\vec{r}_j\,\frac{n(\vec{r}_i)n(\vec{r}_j)}{|\vec{r}_i-\vec{r}_j|}
\label{hartree_functional}
\end{equation}

Next, let us consider the expression for kinetic energy in terms of a functional. Within the Thomas--Fermi approximation, the noninteracting kinetic energy is treated locally as that of a uniform (homogeneous) electron gas whose density equals the actual electron density $n(\vec{r}\,)$ at each point in space.
This leads to the Thomas--Fermi kinetic energy functional:

\begin{equation}
    T_\mathrm{TF}[n]=C\int\mathrm{d}\vec{r}\,n^{5/3}(\vec{r}\,)
\label{tf_functional}
\end{equation}

where $C=\frac{3}{10}(3\pi^2)^{2/3}$ for a spin-degenerate electron gas in atomic units.
This form of kinetic energy functional was introduced independently in the seminal works by L.~H.~Thomas~\cite{thomas1927calculation} and E.~Fermi~\cite{fermi1927metodo}.

Moreover, to account for inhomogeneity effects beyond the purely local Thomas--Fermi form, one often adds the von Weizs{\"a}cker gradient correction to the kinetic energy functional.
A detailed discussion can be found in the review by C.~J.~Garc{\i}a-Cervera~\cite{garcia2007efficient}.
In atomic units, it is generally written as:

\begin{equation}
    T_\mathrm{vW}[n] = \frac{1}{8}\int \mathrm{d}\vec{r}\,\frac{\nabla n(\vec{r}\,)\cdot\nabla n(\vec{r}\,)}{n(\vec{r}\,)},
\label{vw_functional}
\end{equation}

It is neither possible nor necessary to enumerate all examples of functionals in condensed matter physics.
In practice, many such functionals depend explicitly on the electron density $n(\vec{r}\,)$ and, in some cases, also on its gradient $\nabla n(\vec{r}\,)$.
For this reason, they are commonly referred to as density functionals.

\subsection{Density functional in quantum mechanics}

In quantum mechanics, it is often convenient to shift the basic variable from the many-body wavefunction to the electron density $n(\vec{r}\,)$.
From this point of view, every relevant physical quantity can be expressed as a functional of the density.
Therefore, we can realize that a functional takes the density function $n(\vec{r}\,)$ as input and returns a quantum-mechanical observable as output.

To describe this process, we first introduce the density operator:

\begin{equation}
    \hat{n}(\vec{r}\,) = \sum_{i=1}^N \delta(\vec{r}-\hat{\vec{r}}_i)
\label{density_operator}
\end{equation}

Next, we can define the electron density of ground state as its expectation value in the ground state:

\begin{equation}
    n(\vec{r}\,)\coloneqq\bra{\Psi_0}\hat{n}(\vec{r}\,)\ket{\Psi_0}
\label{electron_density_definition}
\end{equation}

here, $\ket{\Psi_0}$ denotes the ground state many-body wavefunction, which encodes the full complexity of the current interacting $N$-electron system.
Given an observable represented by an operator $\hat{\Omega}$, its ground state value is evaluated through the expectation value $O$:

\begin{equation}
    O \coloneqq \bra{\Psi_0}\hat{\Omega}\ket{\Psi_0},
\label{electron_density_expectation}
\end{equation}

and hence every ground state observable can be regarded, at least formally, as a functional of the many-body wavefunction: $O[\Psi_0]=O$.

However, the kernel idea of density functional theory is here: for the ground-state properties, the wavefunction dependence can be reduced even further. In our statement, if the density of ground state $n(\vec{r}\,)$ uniquely specifies the corresponding wavefunction of ground state $\Psi_0$,
the expectation value of any operator $\hat{\Omega}$ in the ground state is uniquely determined by the density function $n(\vec{r}\,)$.

Consequently, every ground state observable can be written as a (unique) density functional:

\begin{equation}
    \bra{\Psi_0}\hat{\Omega}\ket{\Psi_0}=O[n(\vec{r})]
\label{ground state_observable}
\end{equation}

Under the usual Hohenberg--Kohn setting (in particular, for a non-degenerate ground state), the density $n(\vec{r}\,)$ uniquely determines the external potential $v_\mathrm{ext}(\vec{r}\,)$ up to an additive constant.
Consequently, $n(\vec{r}\,)$ fixes the hamiltonian and hence the ground state $\ket{\Psi_0}$ (up to an overall phase).
This statement is essentially the central result of the Hohenberg--Kohn theorem~\cite{hohenberg1964inhomogeneous}: in the ground state, all observables are uniquely determined by the electron density.
Accordingly, any ground state observable may be written as a functional of the density alone:

\begin{equation}
    O = O[n(\vec{r}\,)]
\label{ground state_observable}
\end{equation}

This is not merely a change of notation; it marks the conceptual compression from a function of $3N$ variables, $\Psi_0(\vec{r}_1,\cdots,\vec{r}_N)$, to a function of only three spatial variables, $n(\vec{r}\,)$, which is the cornerstone of the practical formulation of DFT.
Historically, the density functional formalism was established in the 1960s through the pioneering work of Hohenberg and Kohn, and was later made computationally practical by the Kohn--Sham scheme~\cite{kohn1965self}.

Since the many-body wavefunction $\Psi$ encodes the full complexity of the system, a natural question is the following: what is the ingredient that actually distinguishes one many-electron system from another?

To answer this, we recall that the quantum dynamics is specified once the hamiltonian is given.

For electronic systems, the kinetic energy operator $\hat{T}$ and the interaction operator $\hat{V}_\mathrm{int}$ have fixed forms, and in the present context we identify $\hat{V}_\mathrm{int}$ with the electron--electron interaction $\hat{V}_\mathrm{ee}$ as in equation~\eqref{reduced_operator_definition}.

Therefore, the system-specific information enters primarily through the external potential $\hat{V}_\mathrm{ext}$, which is generated by the nuclei and any applied fields.
With this in mind, we review the form of hamiltonian:

\begin{equation}
    \hat{H}=\hat{T}+\hat{V}_\mathrm{int}+\hat{V}_\mathrm{ext}
\label{hamiltonian_decomposition}
\end{equation}

In the \subsecrefT{sec:manybody_schrodinger_equation}, we have discussed in detail the explicit forms and physical meanings of the kinetic, external potential, and interaction terms in the many-body hamiltonian.

Let us return to the reduced expression for the hamiltonian in equation~\eqref{atomic_many-body_hamiltonian}.
We observe that two terms are universal, in the sense that their operator forms do not depend on the specific system.

These are the electronic kinetic energy~\eqref{electrons_kinetic},
and the electron--electron Coulomb repulsion~\eqref{electrons_Coulomb}.

Here, we say the external potential $\hat{V}_\mathrm{ext}$ is not universal, because it depends on the specific nuclear configuration and any applied fields. In contrast, the electronic kinetic energy and the electron--electron Coulomb interaction have fixed operator forms.
Therefore, the external potential is the system-defining ingredient: it distinguishes one many-electron system from another.

In fact, once $\hat{V}_\mathrm{ext}$ is given, the hamiltonian is fully specified.
Conversely, if the hamiltonian is known, then in principle we may solve its eigenvalue problem to obtain the eigenstates and eigenvalues.
With the wavefunction known, any observable can be evaluated as the expectation value of the corresponding operator.

This viewpoint motivates the search for compact descriptors that retain the essential information of the ground state.
A central example is the electron density, for an arbitrary state $\ket{\Psi}$, the electron density is defined as the expectation value of the density operator $\hat{n}(\vec{r}\,)$:

\begin{equation}
\begin{aligned}
   n(\vec{r}\,)&=\bra{\Psi}\hat{n}(\vec{r}\,)\ket{\Psi} \\
   &=\bra{\Psi}\sum_i \delta(\vec{r}-\hat{\vec{r}}_i)\ket{\Psi}
\end{aligned}
\label{electron_densit_via_expectation}
\end{equation}

Consider a fixed form of interaction, the external potential $v_\mathrm{ext}(\vec{r}\,)$ specifies the corresponding hamiltonian and therefore the ground state structure.
Here $v_\mathrm{ext}(\vec{r}\,)$ is a scalar potential field in real space, whereas $\hat{V}_\mathrm{ext}$ is the associated many-body operator acting on the $N$-electron wavefunction.

Given definition of external potential operator~\eqref{reduced_operator_definition}, in coordinate representation, $\hat{V}_\mathrm{ext}$ acts by multiplication with $\sum_i v_\mathrm{ext}(\hat{\vec{r}}_i)$. 

For later convenience, we introduce the particle-density operator in the Schrödinger picture~\eqref{Schrodinger-picture_density_operator} and express the same operator in terms of it.
Since $v_\mathrm{ext}(\vec{r}\,)$ then couples locally to the density operator $\hat{n}(\vec{r}\,)$, we obtain:

\begin{equation}
    \hat{V}_\mathrm{ext}=\int\mathrm{d}\vec{r}\,v_\mathrm{ext}(\vec{r}\,)\,\hat{n}(\vec{r}\,)
\label{local_external_potential_operator_definition}
\end{equation}

Taking the expectation value on an arbitrary state $\ket{\Psi}$ yields the corresponding external potential energy. Using the expectation of density operator as in
equation~\eqref{electron_densit_via_expectation}, we have:

\begin{equation}
    \braket{\hat{V}_\mathrm{ext}}=\int\mathrm{d}\vec{r}\,v_\mathrm{ext}(\vec{r}\,)\,n(\vec{r}\,)
    \label{external_potential_energy_expectation}
\end{equation}

When the ground state is non-degenerate, $v_\mathrm{ext}(\vec{r}\,)$ stands in a one-to-one correspondence (up to an additive constant) with the ground state wavefunction $\Psi_0$.

Consequently, the ground state expectation value of any observable $\hat{O}$ may be viewed as a unique functional of the external potential:

\begin{equation}
   \braket{\hat{O}}\coloneqq \bra{\Psi_0}\hat{O}\ket{\Psi_0}=O[v_\mathrm{ext}]
\label{functional_from_external_potential}
\end{equation}

The central move of density functional theory is to further replace the dependence on the wavefunction by a dependence on the electron density $n(\vec{r}\,)$. The key question is whether the map from external potential $v_\mathrm{ext}(\vec{r}\,)$ to the ground state density $n(\vec{r}\,)$ is likewise invertible in an appropriate sense. The first Hohenberg--Kohn theorem answers this in the affirmative for non-degenerate ground states: the ground state density $n(\vec{r}\,)$ uniquely determines $v_\mathrm{ext}(\vec{r}\,)$ (again up to an additive constant), and hence uniquely fixes the hamiltonian and the corresponding ground state. In this sense, all ground state observables can be regarded as functionals of the density:

\begin{equation}
    \braket{\hat{O}}=O[n(\vec{r}\,)]
\label{functional_from_expectation}
\end{equation}

In the presence of ground state degeneracy, the strict one-to-one correspondence must be understood at the level of the ground state subspace; certain observables may then depend on the particular choice of degenerate ground state. This issue is commonly handled through an ensemble formulation (or via a symmetry-breaking limit) to recover a single-valued density-functional description.

% \subsection{Uniqueness of the ground state with respect to the external potential}
\subsection{The Hohenberg--Kohn theorem}

In this subsection, we focus on the Hohenberg--Kohn theorem, which provides the conceptual foundation of density functional theory: for a fixed form of electron--electron interaction and a non-degenerate ground state, it establishes a one-to-one correspondence between the external potential and the ground state density (up to an additive constant), and it leads to a variational characterization of the ground state.

We begin by proving that, up to an additive constant in the potential, the ground state wavefunction is uniquely determined by the external potential.

We start with assuming for contradiction that two different external potentials lead to the same ground state wavefunction $\ket{\Psi_0}$, while not differing by a mere additive constant:

\begin{equation}
    v^{(1)}_\mathrm{ext}(\vec{r}\,)\neq v^{(2)}_\mathrm{ext}(\vec{r}\,)+\mathrm{const.}
\label{V_ext}
\end{equation}

Next, consider the corresponding hamiltonians and their ground state eigenvalue equations:

\begin{equation}
\begin{aligned}
    \hat{H}_1=\hat{T}+\hat{V}_\mathrm{int}+\hat{V}_\mathrm{ext}^{(1)} &\implies \hat{H}_1\ket{\Psi_0^{(1)}}=E_1\ket{\Psi_0^{(1)}} \\
    \hat{H}_2=\hat{T}+\hat{V}_\mathrm{int}+\hat{V}_\mathrm{ext}^{(2)} &\implies \hat{H}_2\ket{\Psi_0^{(2)}}=E_2\ket{\Psi_0^{(2)}}
\end{aligned}
\label{different_hamiltonians_schrodinger_equation}
\end{equation}

Subtracting the two equations yields:

\begin{equation}
    (\hat{H}_1-\hat{H}_2)\ket{\Psi_0}=(E_1-E_2)\ket{\Psi_0}
\label{difference_eigen}
\end{equation}

Review the expression of the external potential operator in equation~\eqref{reduced_operator_definition}.
Since $\hat{T}$ and $\hat{V}_\mathrm{int}$ are identical in $\hat{H}_1$ and $\hat{H}_2$, the difference comes entirely from the external potential term.
Therefore, for an $N$-electron system, we have:

\begin{equation}
\begin{aligned}
    \sum_{i=1}^N\left[v_\mathrm{ext}^{(1)}(\vec{r}_i)-v_\mathrm{ext}^{(2)}(\vec{r}_i)\right]\ket{\Psi_0}
    &= (\hat{V}_\mathrm{ext}^{(1)}-\hat{V}_\mathrm{ext}^{(2)})\ket{\Psi_0} \\
    &= (E_1-E_2)\ket{\Psi_0}
\end{aligned}
\label{energy_difference}
\end{equation}

Whenever the wavefunction $\Psi_0(\vec{r}_1,\vec{r}_2,\cdots,\vec{r}_N)\neq 0$, we can divide both sides by $\Psi_0$ and obtain:

\begin{equation}
    \sum_{i=1}^N\left[v_\mathrm{ext}^{(1)}(\vec{r}_i)-v_\mathrm{ext}^{(2)}(\vec{r}_i)\right]=E_1-E_2
\label{difference_energy_nowave}
\end{equation}

The equality above implies that, for any configuration $(\vec{r}_1,\vec{r}_2,\cdots,\vec{r}_N)$ where the wavefunction $\Psi_0(\vec{r}_1,\vec{r}_2,\cdots,\vec{r}_N)\neq 0$, the factor multiplying $\Psi_0$ must be constant.
Dividing both sides by $\Psi_0$ wherever the ground-state wavefunction $\Psi_0(\vec{r}_1,\ldots,\vec{r}_N)$ is nonzero, we obtain a constraint on the difference between the two external potentials.

To make this explicit, we define the potential shift function:

\begin{equation}
    g(\vec{r}\,)\coloneqq v_\mathrm{ext}^{(1)}(\vec{r}\,)-v_\mathrm{ext}^{(2)}(\vec{r}\,)
\label{shift_potential}
\end{equation}

Then, we can rewrite the previous relation as:

\begin{equation}
    g(\vec{r}_1)+g(\vec{r}_2)+\cdots+g(\vec{r}_N)=E_1-E_2
\label{N-body_shift_potential}
\end{equation}

for all configurations on which the wavefunction $\Psi_0(\vec{r}_1,\vec{r}_2,\cdots,\vec{r}_N)$ is nonzero.

Now, we pick any set of coordinates $(\vec{r}_2,\cdots,\vec{r}_N)$ such that the wavefunction does not vanish, and keep them fixed.
With these coordinates held fixed, the sum of the last $N-1$ terms,
$g(\vec{r}_2)+\cdots+g(\vec{r}_N)$, is just a scalar.
The equation then reduces to:

\begin{equation}
    g(\vec{r}_1)= (E_1-E_2)-\left[g(\vec{r}_2)+\cdots+g(\vec{r}_N)\right]
\label{fixed_N-body_shift_potential}
\end{equation}

which shows that $g(\vec{r}_1)$ cannot change as $\vec{r}_1$ varies within any region where the wavefunction remains nonzero.
Otherwise the left-hand side would vary with $\vec{r}_1$, while the right-hand side remains fixed.

Since the same argument applies when we vary any other particle coordinate $\vec{r}_j$ with the remaining coordinates fixed,
we conclude that $g(\vec{r}\,)$ must be a constant almost everywhere on the set where $\Psi_0(\vec{r}_1,\ldots,\vec{r}_N)$ is nonzero.
Thus, we arrive at the following relation:

\begin{equation}
    v_\mathrm{ext}^{(1)}(\vec{r}\,)=v_\mathrm{ext}^{(2)}(\vec{r}\,)+\mathrm{const.}
\label{parallel_wavefunction}
\end{equation}

Hence $(E_1-E_2)/N$ is a constant. This contradicts the assumption in equation~\eqref{V_ext}.
Therefore, we arrive at a conclusion that two different external potentials cannot lead to the same non-degenerate ground state wavefunction unless they differ only by an additive constant, as stated in equation~\eqref{parallel_wavefunction}.

Equivalently, up to a constant shift in the potential and for a fixed form of interaction, the mapping from the external potential to the non-degenerate ground state wavefunction is one-to-one.

% \subsection{The Hohenberg--Kohn theorem}

Since any ground state observable follows uniquely from the ground state wavefunction via its expectation value, equation~\eqref{functional_from_external_potential} implies that $\ket{\Psi_0}$ is uniquely determined by $v_\mathrm{ext}$, and hence the ground state observables are unique functionals of $v_\mathrm{ext}$.
The external potential is defined to an additive constant shift.

A natural question then is: what is the relation between the external potential $v_\mathrm{ext}(\vec{r}\,)$ and the density of the current system $n(\vec{r}\,)$?

To describe the statements precise, we next define the equivalence class of external potential $v_\mathrm{ext}(\vec{r}\,)$ and the ground state wavefunction $\ket{\Psi_0}$ as:

\begin{equation}
\begin{aligned}
    \left[v_\mathrm{ext}\right]&\coloneqq\left\{ v_\mathrm{ext}(\vec{r}\,) +\mathrm{const.}\right\}\\
    \left[\ket{\Psi_0}\right]&\coloneqq\left\{\mathrm{e}^{\mathrm{i}\theta}\ket{\Psi_0} \,\middle|\,\theta\in\mathbb{R}\right\}
\end{aligned}
\label{equivalence_classes_definition}
\end{equation}

To address this question, we fix the form of interaction and restrict ourselves to a non-degenerate ground state.
Under these assumptions, there is a one-to-one correspondence between the equivalence class of external potential $\left[v_\mathrm{ext}(\vec{r}\,)\right]$ and the ground state wavefunction $\left[\ket{\Psi_0}\right]$, 
where $\left[v_\mathrm{ext}(\vec{r}\,)\right]$ is defined up to an additive constant and $\left[\ket{\Psi_0}\right]$ up to an overall phase.

Equivalently, $\left[v_\mathrm{ext}(\vec{r}\,)\right]$ and $\left[\ket{\Psi_0}\right]$ are in bijection:

\begin{equation}
    \left[v_\mathrm{ext}(\vec{r}\,)\right]\,\xleftrightarrow{}\,\left[\ket{\Psi_0}\right]
    \label{potential_wavefunction_correspondence}
\end{equation}

Moreover, the wavefunction is directly related to the density through the standard marginalization over the remaining $N-1$ particles. As a result, we obtain a unique ground state density, given by the usual marginalization of the squared modulus of the wavefunction over all but one space variables:

\begin{equation}
    n(\vec{r}\,)=N\int \mathrm{d}\vec{r}_2\cdots\mathrm{d}\vec{r}_N\,\left|\Psi(\vec{r},\vec{r}_2,\cdots,\vec{r}_N)\right|^2
\label{density_function}
\end{equation}

where $\Psi$ is normalized and $N$ is the number of particles.
This means that the external potential $v_\mathrm{ext}$ induces a mapping to the ground state density $n(\vec r\,)$, which this subsection further clarifies the character of this mapping.

The strategy to establish this relation is also a reductio ad absurdum argument.
Suppose there exist two different external potentials $v^{(1)}_\mathrm{ext}(\vec{r}\,)$ and $v^{(2)}_\mathrm{ext}(\vec{r}\,)$ such that $v^{(1)}_\mathrm{ext}(\vec{r}\,)\neq v^{(2)}_\mathrm{ext}(\vec{r}\,)+\mathrm{const.}$
Let their corresponding non-degenerate ground state wavefunctions be denoted as $\Psi_0^{(1)}$ and $\Psi_0^{(2)}$.

Recall the Schrödinger equation~\eqref{different_hamiltonians_schrodinger_equation}.
The external potentials $v^{(1)}_\mathrm{ext}(\vec{r}\,)$ and $v^{(2)}_\mathrm{ext}(\vec{r}\,)$ lead to the eigenvalues $E_1$ and $E_2$, and the corresponding ground state wavefunctions $\ket{\Psi_0^{(1)}}$ and $\ket{\Psi_0^{(2)}}$, respectively.
Since the ground states are assumed non-degenerate: $\ket{\Psi_0^{(1)}}\neq\ket{\Psi_0^{(2)}}$.
For each external potential, the total energy can be written as the expectation value of the hamiltonian in its ground state:

\begin{equation}
\begin{aligned}
    E_1 &= \bra{\Psi_0^{(1)}}\hat{H}_1\ket{\Psi_0^{(1)}} \\
    E_2 &= \bra{\Psi_0^{(2)}}\hat{H}_2\ket{\Psi_0^{(2)}}
\end{aligned}
\label{different_total_energies}
\end{equation}

We now make the key assumption for contradiction: although the two external potentials, and hence the two ground state wavefunctions, are different, they lead to the same ground state density $n^{(1)}(\vec{r}\,)=n^{(2)}(\vec{r}\,)$, where $n^{(1)}(\vec{r}\,)$ and $n^{(2)}(\vec{r}\,)$ are obtained from $\Psi_0^{(1)}$ and $\Psi_0^{(2)}$, respectively, via equation~\eqref{density_function}

Through the Rayleigh--Ritz variational principle: for the ground state energy $E_0$ of a given hamiltonian $\hat{H}$, the energy expectation value over any normalized trial wavefunction $\Phi$ provides an upper bound to the ground state energy:

\begin{equation}
    E_0\leq \bra{\Phi}\hat{H}\ket{\Phi}
\label{Rayleigh-Ritz_principle}
\end{equation}

Therefore, using $\ket{\Psi_0^{(2)}}$ as a trial state for $\hat{H}_1$ and using $\ket{\Psi_0^{(1)}}$ as a trial state for $\hat{H}_2$, we obtain:

\begin{equation}
\begin{aligned}
    E_1&=\bra{\Psi_0^{(1)}}\hat{H}_1\ket{\Psi_0^{(1)}}<\bra{\Psi_0^{(2)}}\hat{H}_1\ket{\Psi_0^{(2)}}\\
    E_2&=\bra{\Psi_0^{(2)}}\hat{H}_2\ket{\Psi_0^{(2)}}<\bra{\Psi_0^{(1)}}\hat{H}_2\ket{\Psi_0^{(1)}}
\end{aligned}
\label{Rayleigh-Ritz_principle_application}
\end{equation}

where the strict inequalities follow from the assumption that the ground state is non-degenerate and that $\ket{\Psi_0^{(1)}}\neq\ket{\Psi_0^{(2)}}$.

Let us rewrite the variational bound for $E_1$.
Recall the eigenvalue equation~\eqref{difference_eigen} and the definition of the hamiltonian difference in equation~\eqref{energy_difference}.
We can  expand the right-hand side as:

\begin{equation}
\begin{aligned}
    E_1=\bra{\Psi_0^{(1)}}\hat{H}_1\ket{\Psi_0^{(1)}}<\bra{\Psi_0^{(2)}}\hat{H}_1\ket{\Psi_0^{(2)}}
    &=\bra{\Psi_0^{(2)}}(\hat{H}_1-\hat{H}_2+\hat{H}_2)\ket{\Psi_0^{(2)}} \\
    &=\bra{\Psi_0^{(2)}}\hat{H}_2\ket{\Psi_0^{(2)}}
      +\bra{\Psi_0^{(2)}}(\hat{H}_1-\hat{H}_2)\ket{\Psi_0^{(2)}} \\
    &=E_2+\bra{\Psi_0^{(2)}}(\hat{V}_\mathrm{ext}^{(1)}-\hat{V}_\mathrm{ext}^{(2)})\ket{\Psi_0^{(2)}} \\
\end{aligned}
\label{H1_expectation_expansion}
\end{equation}

The further step is to rewrite the last term in a density form.
Let us apply the definition of the electron density function~\eqref{electron_densit_via_expectation} as:

\begin{equation}
    n^{(2)}(\vec{r}\,) = \bra{\Psi_0^{(2)}}\hat{n}(\vec{r}\,)\ket{\Psi_0^{(2)}}
\label{density_expectation_definition}
\end{equation}

Then, we apply the definition of the operator for external potential~\eqref{local_external_potential_operator_definition}, and obtain:

\begin{equation}
\begin{aligned}
    \bra{\Psi_0^{(2)}}(\hat{V}_\mathrm{ext}^{(1)}-\hat{V}_\mathrm{ext}^{(2)})\ket{\Psi_0^{(2)}}
    &=\int \mathrm{d}\vec{r}\,\left[v_\mathrm{ext}^{(1)}(\vec{r}\,)-v_\mathrm{ext}^{(2)}(\vec{r}\,)\right]\,\bra{\Psi_0^{(2)}}\hat{n}(\vec{r}\,)\ket{\Psi_0^{(2)}} \\
    &=\int \mathrm{d}\vec{r}\,\left[v_\mathrm{ext}^{(1)}(\vec{r}\,)-v_\mathrm{ext}^{(2)}(\vec{r}\,)\right]\,n^{(2)}(\vec{r}\,)
\end{aligned}
\label{density_form_vext_difference}
\end{equation}

As a result, the total energy of the first system satisfies the following inequality:
\begin{equation}
    E_1<E_2+\bra{\Psi_0^{(2)}}\big(\hat{V}_\mathrm{ext}^{(1)}-\hat{V}_\mathrm{ext}^{(2)}\big)\ket{\Psi_0^{(2)}}
\end{equation}

Therefore, we arrive at the following inequality for the ground state energies:

\begin{equation}
    E_1<E_2+\int \mathrm{d}\vec{r}\,\left[v_\mathrm{ext}^{(1)}(\vec{r}\,)-v_\mathrm{ext}^{(2)}(\vec{r}\,)\right]\,\,n^{(2)}(\vec{r}\,)
\label{total_energy_inequality_E1}
\end{equation}

Vice versa, upon interchanging the roles of the two systems, we analogously obtain:

\begin{equation}
    E_2<E_1+\int \mathrm{d}\vec{r}\,\left[v_\mathrm{ext}^{(2)}(\vec{r}\,)-v_\mathrm{ext}^{(1)}(\vec{r}\,)\right]\,\,n^{(1)}(\vec{r}\,)
\label{total_energy_inequality_E2}
\end{equation}

We are now ready to complete the reductio ad absurdum argument.
Revisit our assumption that two distinct external potentials $v_\mathrm{ext}^{(1)}(\vec{r}\,)\neq v_\mathrm{ext}^{(2)}(\vec{r}\,)$ yield the same ground state density $n(\vec{r}\,)=n^{(1)}(\vec{r}\,)=n^{(2)}(\vec{r}\,)$, the Rayleigh--Ritz variational principle leads to the previous ground state energy inequalities.

Using $n(\vec{r}\,)=n^{(1)}(\vec{r}\,) = n^{(2)}(\vec{r}\,)$ and adding equations~\eqref{total_energy_inequality_E1}
and~\eqref{total_energy_inequality_E2}, the integral terms cancel identically, which leads to:

\begin{equation}
    E_1 + E_2 < E_1 + E_2
\label{total_energy_inequality_contradiction}
\end{equation}

It is obviously a contradiction.
This demonstrates that, for a fixed form of interaction and a non-degenerate ground state,
the ground state density $n(\vec{r}\,)$ uniquely determines the external potential $v_\mathrm{ext}(\vec{r}\,)$ up to an additive constant,
and hence uniquely determines the hamiltonian and the ground state up to an overall phase.

Let us recollect the definition of the equivalence class of the external potential $v_\mathrm{ext}(\vec{r}\,)$ and the ground state wavefunction $\ket{\Psi_0}$ in equation~\eqref{equivalence_classes_definition},
as well as the fact that the equivalence classes $\left[v_\mathrm{ext}\right]$ and $\left[\ket{\Psi_0}\right]$ are in bijection in equation~\eqref{potential_wavefunction_correspondence}.

Moreover, the ground state wavefunction uniquely determines the ground state density via the standard marginalization:

\begin{equation}
    \left[\ket{\Psi_0}\right]\longmapsto n(\vec{r}\,)
    \label{wavefunction_density_map}
\end{equation}

We emphasize that the map in equation~\eqref{wavefunction_density_map} is not injective for any arbitrary many-body wavefunction.
In the present setting, however, we restrict ourselves to non-degenerate ground states. Within this restricted class, the first Hohenberg--Kohn theorem provides a unique inverse implication, namely that the ground state density uniquely determines the equivalence class of the external potential:

\begin{equation}
    n(\vec{r}\,)\longmapsto\left[v_\mathrm{ext}(\vec{r}\,)\right]
    \label{density_potential_map}
\end{equation}

Combining equations~\eqref{potential_wavefunction_correspondence}, \eqref{wavefunction_density_map},
and\eqref{density_potential_map}, we finally arrive at a one-to-one correspondence among the basic ground state descriptors:

\begin{equation}
    \left[v_\mathrm{ext}(\vec{r}\,)\right]\;\xleftrightarrow{}\; n(\vec{r}\,)\;\xleftrightarrow{}\;\left[\ket{\Psi_0}\right]
    \label{hk_correspondence_v_n_psi}
\end{equation}

The two previous equations~\eqref{density_potential_map} and~\eqref{hk_correspondence_v_n_psi} summarize the content of the Hohenberg--Kohn theorem~\cite{hohenberg1964inhomogeneous}.
For a fixed form of interaction and a non-degenerate ground state, the ground state density $n(\vec{r}\,)$ is in bijection with the equivalence class of the external potential $\left[v_\mathrm{ext}(\vec{r}\,)\right]$ up to an additive constant. 
Consequently, the ground state density uniquely determines the hamiltonian and the ground state wavefunction up to an overall phase,
and any ground state observable is, in principle, a unique functional of $n(\vec{r}\,)$.

Therefore, the ground state expectation definition~\eqref{functional_from_external_potential} can be reformulated as:

\begin{equation}
   \braket{\hat{O}}= \bra{\Psi_0}\hat{O}\ket{\Psi_0}=O[n(\vec{r}\,)]
\label{functional_from_density}
\end{equation}

here, $O[n(\vec{r}\,)]$ denotes the density functional that yields the ground state expectation value of $\hat{O}$.
This observation forms the central premise of density functional theory and motivates the use of the density, rather than the wavefunction, as the fundamental variable.

As described by equation~\eqref{functional_from_density},
every ground state observable is a unique functional of the electron density.

Recall equation~\eqref{eigenenergy_as_expectation_value}, which expresses the ground state energy as the expectation value of the hamiltonian.
According to decomposition of the hamiltonian in equation~\eqref{hamiltonian_decomposition}, we write:

\begin{equation}
\begin{aligned}
    E_0
    &= \bra{\Psi_0}\hat{H}\ket{\Psi_0} \\
    &= \bra{\Psi_0}(\hat{T}+\hat{V}_\mathrm{int}+\hat{V}_\mathrm{ext})\ket{\Psi_0}
\end{aligned}
\label{groundstate_energy_decomposition}
\end{equation}

To generalize this variational picture, for a given admissible density $n(\vec{r}\,)$ we consider wavefunctions $\Psi$ that yield $n$, and define

\begin{equation}
\begin{aligned}
    E[n]
    &= \min_{\Psi\to n}\bra{\Psi}(\hat{T}+\hat{V}_\mathrm{int}+\hat{V}_\mathrm{ext})\ket{\Psi} \\
    &= \bra{\Psi[n]}(\hat{T}+\hat{V}_\mathrm{int}+\hat{V}_\mathrm{ext})\ket{\Psi[n]}
\end{aligned}
\label{functional_energy_constrained_search}
\end{equation}

which reduces to $E_0$ when $n=n_0$.

Here the minimization is taken over all normalized antisymmetric $N$-electron wavefunctions $\ket{\Psi}$ compatible with the fixed interaction.

The kinetic energy functional $T[n]$, the interaction energy functional $E_\mathrm{int}[n]$, and the external potential energy functional $E_\mathrm{ext}[n]$ are evaluated on a minimizing wavefunction $\Psi[n]$ that yields the density $n$. We now write their definitions:

\begin{equation}
\begin{aligned}
    T[n]&\coloneqq\bra{\Psi[n]}\hat{T}\ket{\Psi[n]} \\
    E_\mathrm{int}[n]&\coloneqq\bra{\Psi[n]}\hat{V}_\mathrm{int}\ket{\Psi[n]} \\
    E_\mathrm{ext}[n]&\coloneqq\bra{\Psi[n]}\hat{V}_\mathrm{ext}\ket{\Psi[n]}
\end{aligned}
\label{functional_T_Eint_Eext_definition}
\end{equation}

Using the local form of the external potential operator in equation~\eqref{local_external_potential_operator_definition}, we get the local form of the external potential energy functional:

\begin{equation}
    E_\mathrm{ext}[n]=\int\mathrm{d}\vec{r}\,v_\mathrm{ext}(\vec{r}\,)\,n(\vec{r}\,)
    \label{functional_Eext_local_form}
\end{equation}

According to the definition of the ground state density in equation~\eqref{electron_density_definition},
as well as the definitions of the kinetic energy and interaction energy functionals in equation~\eqref{functional_T_Eint_Eext_definition},
we obtain:

\begin{equation}
\begin{aligned}
E[n]
&= \bra{\Psi[n]}(\hat{T}+\hat{V}_\mathrm{int}+\hat{V}_\mathrm{ext})\ket{\Psi[n]} \\
&= \bra{\Psi[n]}(\hat{T}+\hat{V}_\mathrm{int})\ket{\Psi[n]}
 + \int\mathrm{d}\vec{r}\,v_\mathrm{ext}(\vec{r}\,)\,n(\vec{r}\,) \\
&= T[n]+E_\mathrm{int}[n]+\int\mathrm{d}\vec{r}\,v_\mathrm{ext}(\vec{r}\,)\,n(\vec{r}\,).
\end{aligned}
\label{functional_energy_density_decomposition}
\end{equation}

To proceed, we separate the system-specific external potential contribution from the remaining part of the energy.
This motivates introducing the universal Hohenberg--Kohn functional $F_\mathrm{HK}[n]$, defined by a constrained-search formulation~\cite{levy1979universal,engel2011density}:

\begin{equation}
\begin{aligned}
    F_\mathrm{HK}[n]
    &= \min_{\Psi\to n}\bra{\Psi}(\hat{T}+\hat{V}_\mathrm{int})\ket{\Psi} \\
    &= T[n] + E_\mathrm{int}[n]
\end{aligned}
\label{functional_HK_definition}
\end{equation}

For a fixed form of the electron-electron interaction, $F_\mathrm{HK}[n]$ is independent of the external potential $v_\mathrm{ext}(\vec{r}\,)$,
and the system specific information enters only through $v_\mathrm{ext}$.

With this definition, the total energy density functional can be written in the standard form:

\begin{equation}
    E[n]=F_\mathrm{HK}[n]+\int\mathrm{d}\vec{r}\,v_\mathrm{ext}(\vec{r}\,)\,n(\vec{r}\,)
    \label{standard_form_energy_functional}
\end{equation}

The Hohenberg--Kohn theorem then allows us to cast the ground state problem as a constrained search over admissible densities:

\begin{equation}
    E_0 = \min_{n(\vec{r}\,)}\left\{E\,\left[n(\vec{r}\,)\right]\,|\,\int \mathrm{d}\vec{r}\,n(\vec{r}\,)
    = N\right\}= E\,\left[n_0(\vec{r}\,)\right].
    \label{density_minimization_principle}
\end{equation}

Conceptually, equation~\eqref{density_minimization_principle} defines an underlying energy surface over the space of admissible densities; figure~\ref{figure_HK_variational} provides a two-dimensional schematic slice of such a high-dimensional landscape.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.8\textwidth]{figures_ch2/HK_variational.pdf}
  \caption{Schematic illustration of the Hohenberg--Kohn variational picture}
  \label{figure_HK_variational}
\end{figure}

This is not exactly how density functional theory works in practice,
or at least in the majority of applications,
but it provides a clear variational picture of the underlying idea.

We now enforce the particle number constraint to carry out the constrained minimization in equation~\eqref{density_minimization_principle}.

To this goal, we impose the particle number condition:

\begin{equation}
    \int \mathrm{d}\vec{r}\, n(\vec{r}\,) = N
    \label{particle_number_constraint}
\end{equation}

by introducing a Lagrange multiplier $\mu$ and defining the auxiliary functional:

\begin{equation}
    \widetilde{E}[n]\coloneqq E[n]-\mu\left(\int\mathrm{d}\vec{r}\,n(\vec{r}\,)-N\right)
    \label{lagrangian_functional_density}
\end{equation}

At the minimum, the first variation vanishes for all admissible $\delta n(\vec{r}\,)$, which gives the Euler--Lagrange condition:

\begin{equation}
    \frac{\delta E[n]}{\delta n(\vec{r}\,)} = \mu
    \label{euler_lagrange_density_general}
\end{equation}

Combining the Euler--Lagrange condition in equation~\eqref{euler_lagrange_density_general} with the standard form of the energy functional in equation~\eqref{standard_form_energy_functional}, we obtain:

\begin{equation}
    \frac{\delta F_\mathrm{HK}[n]}{\delta n(\vec{r}\,)} + v_\mathrm{ext}(\vec{r}\,) = \mu
    \label{euler_lagrange_density_functional}
\end{equation}

evaluated at $n=n_0$.

However, the functional $F_\mathrm{HK}[n]$ (and hence its components such as the kinetic and interaction contributions)
is not known explicitly as a functional of the density, and must be approximated in practical calculations.

At this point, we return to the standard form of the energy functional in equation~\eqref{standard_form_energy_functional}. By rearranging it, we can formally write the universal Hohenberg--Kohn functional as:

\begin{equation}
    F_\mathrm{HK}[n] = E[n]-\int\mathrm{d}\vec{r}\,v_\mathrm{ext}(\vec{r}\,)\,n(\vec{r}\,)
    \label{formal_FHK_as_difference}
\end{equation}
This relation may suggest that $F_\mathrm{HK}[n]$ could be obtained once the total energy functional $E[n]$ is known.

In practice, this is not a constructive route.
For a given $v_\mathrm{ext}(\vec{r}\,)$, the interacting many-body problem yields only the minimizing density $n_0(\vec{r}\,)$ and the corresponding energy $E[n_0]$.
To determine a functional over a broad range of densities, we would in principle need to solve the interacting problem for many different external potentials to sample many ground state densities.
Therefore, the Hohenberg--Kohn theorem should be viewed as an existence and uniqueness statement, rather than an explicit formula for $F_\mathrm{HK}[n]$. 

These considerations clarify why density functional theory relies on approximations.
In what follows, we introduce the Kohn--Sham construction,
which reorganizes the problem so that a large part of the functional can be treated exactly,
and the remaining unknown part can be approximated systematically.

\subsection{The Thomas--Fermi approach}

Now, we introduce the Thomas--Fermi approach as a first and purely density-based model for the kinetic energy.

The basic idea is to treat the electrons locally as a uniform, spin-degenerate Fermi gas.
At each point $\vec{r}$, the local density $n(\vec{r}\,)$ fixes a local Fermi momentum $p_F(\vec{r}\,)$, which allows us to estimate the kinetic energy density from the occupied Fermi sphere in momentum space.

For a spin-degenerate system, the phase-space counting gives:

\begin{equation}
    n(\vec{r}\,) = \frac{2}{h^3}\frac{4\pi}{3}\,p_F^3(\vec{r}\,)
    \label{TF_density_pf_intro}
\end{equation}

and the local Fermi momentum is related to the local single particle energy through:

\begin{equation}
    \mu = \frac{p_F^2(\vec{r}\,)}{2m}+V(\vec{r}\,)
    \label{TF_mu_local_intro}
\end{equation}

Combining these two expressions yields a local relation between $n(\vec{r}\,)$ and $V(\vec{r}\,)$.
This relation also leads to an explicit approximation for the kinetic energy functional in terms of $n(\vec{r}\,)$ alone, which we introduce next.

To close the Thomas--Fermi picture, we treat $V(\vec{r}\,)$ as an electrostatic potential generated self-consistently by the electron density.
In atomic units, it satisfies the Poisson equation:

\begin{equation}
    \nabla^2 V(\vec{r}\,) = -4\pi\,n(\vec{r}\,)
    \label{TF_poisson_equation}
\end{equation}

Eliminating $p_F(\vec{r}\,)$ between \eqref{TF_density_pf_intro} and \eqref{TF_mu_local_intro}, we obtain:

\begin{equation}
    n(\vec{r}\,) = \frac{1}{3\pi^2}\,[2(\mu - V(\vec{r}\,))]^{3/2}
    \label{TF_density_muV}
\end{equation}

Substituting this expression into equation~\eqref{TF_poisson_equation},
We arrive at the Thomas--Fermi equation:

\begin{equation}
    \nabla^2 V(\vec{r}\,)=-\frac{4}{3\pi}\,[2(\mu-V(\vec{r}\,))]^{3/2}
    \label{thomas_fermi_equation}
\end{equation}

This nonlinear equation determines the potential and the density self-consistently within the Thomas--Fermi approximation.

To connect the Thomas--Fermi construction with density functional theory, we rewrite the total energy in a density functional form, denoted by $E^{\mathrm{TF}}[n;v_\mathrm{ext}]$. In this sense, the Thomas--Fermi model provides an explicit approximation to the universal functional.

From the Thomas--Fermi approximation, we express the total energy as a density functional composed of a statistical kinetic term $T_\mathrm{TF}[n]$, an interaction term $E_\mathrm{int}[n]$, and an external contribution $E_\mathrm{ext}[n]$ describing the coupling to $v_\mathrm{ext}(\vec{r}\,)$. Accordingly, we write:

\begin{equation}
    E^{\mathrm{TF}}[n;v_\mathrm{ext}] = T_\mathrm{TF}[n] + E_\mathrm{int}[n] + E_\mathrm{ext}[n]
    \label{TF_total_energy_functional}
\end{equation}


%P1 1:27

\newpage
\section{From density functional to Kohn--Sham theory}

\newpage
\section{Approximation and strategies in density functional theory}
